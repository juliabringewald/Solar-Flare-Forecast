{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#BINARY CLASSIFICATION - 8PC\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve, average_precision_score, roc_curve, auc, f1_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.utils import resample\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv(\"8 PC.csv\")\n",
        "\n",
        "# Ensure class distributions\n",
        "print(\"Original Class Distribution:\")\n",
        "print(df['flare_class_encoded'].value_counts())\n",
        "\n",
        "# Impute missing values (debugging approach propsed by Gemini AI)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df[df.columns] = imputer.fit_transform(df)\n",
        "\n",
        "df = df.copy()\n",
        "\n",
        "# Update labels for binary classification\n",
        "def encode_binary_class(row):\n",
        "    if row['flare_class_encoded'] < 300:\n",
        "        return 0  # B/C class\n",
        "    else:\n",
        "        return 1  # M/X class\n",
        "\n",
        "# copy to avoid df fragmentation\n",
        "df['binary_class'] = df.apply(encode_binary_class, axis=1)\n",
        "df = df.copy()\n",
        "\n",
        "print(\"Binary Class Distribution:\")\n",
        "print(df['binary_class'].value_counts())\n",
        "\n",
        "def create_binary_splits(n_repeats=100):\n",
        "    all_splits = []\n",
        "    for repeat in range(n_repeats):\n",
        "        try:\n",
        "            # Randomly select unique samples for each binary class\n",
        "            bc_class_samples = resample(df[df['binary_class'] == 0], replace=False, n_samples=165, random_state=repeat)\n",
        "            mx_class_samples = resample(df[df['binary_class'] == 1], replace=False, n_samples=165, random_state=repeat)\n",
        "            complete_data = pd.concat([bc_class_samples, mx_class_samples])\n",
        "            X = complete_data.drop(columns=['flare_class_encoded', 'binary_class']) # feature values\n",
        "            y = complete_data['binary_class']  # Target value\n",
        "            all_splits.append((X, y))\n",
        "        except ValueError as e:\n",
        "            print(f\"Repeat {repeat}: Error - {e}\")\n",
        "            continue\n",
        "    return all_splits\n",
        "\n",
        "# Function to evaluate model with GridSearchCV\n",
        "def evaluate_model_with_xgboost(X, y, n_splits=10):\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    param_grid = {\n",
        "        'learning_rate': [0.1, 0.9],\n",
        "        'subsample': [0.01, 1]\n",
        "    }\n",
        "\n",
        "    model_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "    grid_search = GridSearchCV(estimator=model_xgb, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "    accuracy_scores = []\n",
        "    roc_auc_scores = []\n",
        "    pr_auc_scores = []\n",
        "    f1_scores = []\n",
        "    fpr_list = []\n",
        "    tpr_list = []\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        best_model_xgb = grid_search.best_estimator_\n",
        "\n",
        "        y_pred = best_model_xgb.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracy_scores.append(accuracy)\n",
        "\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        test_pred_prob = best_model_xgb.predict_proba(X_test)[:, 1]\n",
        "        roc_auc = roc_auc_score(y_test, test_pred_prob)\n",
        "        roc_auc_scores.append(roc_auc)\n",
        "\n",
        "        precision, recall, _ = precision_recall_curve(y_test, test_pred_prob)\n",
        "        pr_auc = average_precision_score(y_test, test_pred_prob)\n",
        "        pr_auc_scores.append(pr_auc)\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(y_test, test_pred_prob)\n",
        "        fpr_list.append(fpr)\n",
        "        tpr_list.append(tpr)\n",
        "        precision_list.append((precision, len(precision)))\n",
        "        recall_list.append((recall, len(recall)))\n",
        "\n",
        "    return np.mean(accuracy_scores), np.mean(roc_auc_scores), np.mean(pr_auc_scores), np.mean(f1_scores), accuracy_scores, roc_auc_scores, pr_auc_scores, f1_scores, fpr_list, tpr_list, precision_list, recall_list\n",
        "\n",
        "# Evaluate binary classification with 10-fold cross-validation and GridSearchCV\n",
        "binary_splits = create_binary_splits()\n",
        "if len(binary_splits) == 0:\n",
        "    print(\"No valid splits created.\")\n",
        "else:\n",
        "    binary_results = [evaluate_model_with_xgboost(X, y) for X, y in binary_splits]\n",
        "    mean_binary_accuracy = np.mean([result[0] for result in binary_results])\n",
        "    mean_binary_roc_auc = np.mean([result[1] for result in binary_results])\n",
        "    mean_binary_pr_auc_8PC = np.mean([result[2] for result in binary_results])\n",
        "    mean_f1_score = np.mean([result[3] for result in binary_results])\n",
        "\n",
        "    print(f\"Mean Binary Accuracy: {mean_binary_accuracy}\")\n",
        "    print(f\"Mean Binary ROC AUC: {mean_binary_roc_auc}\")\n",
        "    print(f\"Mean Binary PR AUC: {mean_binary_pr_auc_8PC}\")\n",
        "    print(f\"Mean Binary F1 Score: {mean_f1_score}\")\n",
        "\n",
        "    # Plot Mean ROC AUC Curve\n",
        "    mean_fpr_8PC = np.linspace(0, 1, 100)\n",
        "    tpr_interpolated = [np.interp(mean_fpr_8PC, fpr, tpr) for fpr, tpr in zip(binary_results[4][8], binary_results[4][9]) if isinstance(fpr, np.ndarray) and isinstance(tpr, np.ndarray)]\n",
        "    mean_tpr_8PC = np.mean(tpr_interpolated, axis=0)\n",
        "    mean_tpr_8PC[-1] = 1.0\n",
        "    mean_roc_auc_8PC = auc(mean_fpr_8PC, mean_tpr_8PC)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(mean_fpr_8PC, mean_tpr_8PC, color='green', label=f'Mean ROC (8PC) (AUC = {mean_roc_auc_8PC:.2f})', lw=2, alpha=.8)\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=.8)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate', fontsize=16)\n",
        "    plt.ylabel('True Positive Rate', fontsize=16)\n",
        "    plt.title('Mean ROC AUC Curve', fontsize=18)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    # Plot Mean Precision-Recall Curve\n",
        "    precision_interpolated_8PC = [np.interp(mean_fpr_8PC, np.linspace(0, 1, len(precision)), precision) for precision, _ in binary_results[4][10] if isinstance(precision, np.ndarray)]\n",
        "    recall_interpolated_8PC = [np.interp(mean_fpr_8PC, np.linspace(0, 1, len(recall)), recall) for recall, _ in binary_results[4][11] if isinstance(recall, np.ndarray)]\n",
        "    mean_precision_8PC = np.mean(precision_interpolated_8PC, axis=0)\n",
        "    mean_recall_8PC = np.mean(recall_interpolated_8PC, axis=0)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(mean_recall_8PC, mean_precision_8PC, color='green', label=f'Mean PR (8PC) (AUC = {mean_binary_pr_auc_8PC:.2f})', lw=2, alpha=.8)\n",
        "    plt.xlabel('Recall', fontsize=16)\n",
        "    plt.ylabel('Precision', fontsize=16)\n",
        "    plt.title('Mean Precision-Recall Curve', fontsize=18)\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.savefig(\"PR_curve_XGB_BINARY.png\")\n",
        "    plt.show()\n",
        "\n",
        "# Print final class distributions for debugging\n",
        "if len(binary_splits) > 0:\n",
        "    X, y = binary_splits[0]\n",
        "    print(f\"Final Training Set Class Distribution:\\n{y.value_counts()}\")\n"
      ],
      "metadata": {
        "id": "mRiZzfZv5QJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BINARY CLASSIFICATION - 100PC\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv(\"100 PC.csv\")\n",
        "\n",
        "# Ensure class distributions\n",
        "print(\"Original Class Distribution:\")\n",
        "print(df['flare_class_encoded'].value_counts())\n",
        "\n",
        "# Impute missing values (debugging approach propsed by Gemini AI)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df[df.columns] = imputer.fit_transform(df)\n",
        "\n",
        "df = df.copy()\n",
        "\n",
        "# Update labels for binary classification\n",
        "def encode_binary_class(row):\n",
        "    if row['flare_class_encoded'] < 300:\n",
        "        return 0  # B/C class\n",
        "    else:\n",
        "        return 1  # M/X class\n",
        "\n",
        "# copy to avoid df fragmentation\n",
        "df['binary_class'] = df.apply(encode_binary_class, axis=1)\n",
        "df = df.copy()\n",
        "\n",
        "print(\"Binary Class Distribution:\")\n",
        "print(df['binary_class'].value_counts())\n",
        "\n",
        "def create_binary_splits(n_repeats=100):\n",
        "    all_splits = []\n",
        "    for repeat in range(n_repeats):\n",
        "        try:\n",
        "            # Randomly select unique samples for each binary class\n",
        "            bc_class_samples = resample(df[df['binary_class'] == 0], replace=False, n_samples=165, random_state=repeat)\n",
        "            mx_class_samples = resample(df[df['binary_class'] == 1], replace=False, n_samples=165, random_state=repeat)\n",
        "            complete_data = pd.concat([bc_class_samples, mx_class_samples])\n",
        "            X = complete_data.drop(columns=['flare_class_encoded', 'binary_class']) # feature values\n",
        "            y = complete_data['binary_class']  # Target value\n",
        "            all_splits.append((X, y))\n",
        "        except ValueError as e:\n",
        "            print(f\"Repeat {repeat}: Error - {e}\")\n",
        "            continue\n",
        "    return all_splits\n",
        "\n",
        "# Function to evaluate model with GridSearchCV\n",
        "def evaluate_model_with_xgboost(X, y, n_splits=10):\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    param_grid = {\n",
        "        'learning_rate': [0.1, 0.9],\n",
        "        'subsample': [0.01, 1]\n",
        "    }\n",
        "\n",
        "    model_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "    grid_search = GridSearchCV(estimator=model_xgb, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "    accuracy_scores = []\n",
        "    roc_auc_scores = []\n",
        "    pr_auc_scores = []\n",
        "    f1_scores = []\n",
        "    fpr_list = []\n",
        "    tpr_list = []\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        best_model_xgb = grid_search.best_estimator_\n",
        "\n",
        "        y_pred = best_model_xgb.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracy_scores.append(accuracy)\n",
        "\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        test_pred_prob = best_model_xgb.predict_proba(X_test)[:, 1]\n",
        "        roc_auc = roc_auc_score(y_test, test_pred_prob)\n",
        "        roc_auc_scores.append(roc_auc)\n",
        "\n",
        "        precision, recall, _ = precision_recall_curve(y_test, test_pred_prob)\n",
        "        pr_auc = average_precision_score(y_test, test_pred_prob)\n",
        "        pr_auc_scores.append(pr_auc)\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(y_test, test_pred_prob)\n",
        "        fpr_list.append(fpr)\n",
        "        tpr_list.append(tpr)\n",
        "        precision_list.append((precision, len(precision)))\n",
        "        recall_list.append((recall, len(recall)))\n",
        "\n",
        "    return np.mean(accuracy_scores), np.mean(roc_auc_scores), np.mean(pr_auc_scores), np.mean(f1_scores), accuracy_scores, roc_auc_scores, pr_auc_scores, f1_scores, fpr_list, tpr_list, precision_list, recall_list\n",
        "\n",
        "# Evaluate binary classification with 10-fold cross-validation and GridSearchCV\n",
        "binary_splits = create_binary_splits()\n",
        "if len(binary_splits) == 0:\n",
        "    print(\"No valid splits created.\")\n",
        "else:\n",
        "    binary_results = [evaluate_model_with_xgboost(X, y) for X, y in binary_splits]\n",
        "    mean_binary_accuracy = np.mean([result[0] for result in binary_results])\n",
        "    mean_binary_roc_auc = np.mean([result[1] for result in binary_results])\n",
        "    mean_binary_pr_auc_100PC = np.mean([result[2] for result in binary_results])\n",
        "    mean_f1_score = np.mean([result[3] for result in binary_results])\n",
        "\n",
        "    print(f\"Mean Binary Accuracy: {mean_binary_accuracy}\")\n",
        "    print(f\"Mean Binary ROC AUC: {mean_binary_roc_auc}\")\n",
        "    print(f\"Mean Binary PR AUC: {mean_binary_pr_auc_100PC}\")\n",
        "    print(f\"Mean Binary F1 Score: {mean_f1_score}\")\n",
        "\n",
        "     # combined Plot Mean ROC AUC Curve (8;100 PC)\n",
        "    mean_fpr_100PC = np.linspace(0, 1, 100)\n",
        "    tpr_interpolated = [np.interp(mean_fpr_100PC, fpr, tpr) for fpr, tpr in zip(binary_results[4][8], binary_results[4][9]) if isinstance(fpr, np.ndarray) and isinstance(tpr, np.ndarray)]\n",
        "    mean_tpr_100PC = np.mean(tpr_interpolated, axis=0)\n",
        "    mean_tpr_100PC[-1] = 1.0\n",
        "    mean_roc_auc_100PC = auc(mean_fpr_100PC, mean_tpr_100PC)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(mean_fpr_8PC, mean_tpr_8PC, color='violet', label=f'Mean ROC (8PC) (AUC = {mean_roc_auc_8PC:.2f})', lw=2, alpha=.8)\n",
        "    plt.plot(mean_fpr_100PC, mean_tpr_100PC, color='orange', label=f'Mean ROC (100PC) (AUC = {mean_roc_auc_100PC:.2f})', lw=2, alpha=.8)\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=.8)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate', fontsize=16)\n",
        "    plt.ylabel('True Positive Rate', fontsize=16)\n",
        "    plt.title('Mean ROC AUC Curve', fontsize=18)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "     # combined Plot Mean PR Curve (8;100 PC)\n",
        "    precision_interpolated_100PC = [np.interp(mean_fpr_100PC, np.linspace(0, 1, len(precision)), precision) for precision, _ in binary_results[4][10] if isinstance(precision, np.ndarray)]\n",
        "    recall_interpolated_100PC = [np.interp(mean_fpr_100PC, np.linspace(0, 1, len(recall)), recall) for recall, _ in binary_results[4][11] if isinstance(recall, np.ndarray)]\n",
        "    mean_precision_100PC = np.mean(precision_interpolated_100PC, axis=0)\n",
        "    mean_recall_100PC = np.mean(recall_interpolated_100PC, axis=0)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(mean_recall_8PC, mean_precision_8PC, color='violet', label=f'Mean PR (8PC) (AUC = {mean_binary_pr_auc_8PC:.2f})', lw=2, alpha=.8)\n",
        "    plt.plot(mean_recall_100PC, mean_precision_100PC, color='orange', label=f'Mean PR (100PC) (AUC = {mean_binary_pr_auc_100PC:.2f})', lw=2, alpha=.8)\n",
        "    plt.xlabel('Recall', fontsize=16)\n",
        "    plt.ylabel('Precision', fontsize=16)\n",
        "    plt.title('Mean Precision-Recall Curve', fontsize=18)\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.savefig(\"PR_curve_XGB_BINARY.png\")\n",
        "    plt.show()\n",
        "\n",
        "# Print final class distributions for debugging\n",
        "if len(binary_splits) > 0:\n",
        "    X, y = binary_splits[0]\n",
        "    print(f\"Final Training Set Class Distribution:\\n{y.value_counts()}\")\n"
      ],
      "metadata": {
        "id": "wk29oUBtuBGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MULTICLASS CLASSIFICATION - 8PC\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve, average_precision_score, roc_curve, auc, f1_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv(\"8 PC.csv\")\n",
        "\n",
        "# Ensure class distributions\n",
        "print(\"Original Class Distribution:\")\n",
        "print(df['flare_class_encoded'].value_counts())\n",
        "\n",
        "# Impute missing values (debugging approach propsed by Gemini AI)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df[df.columns] = imputer.fit_transform(df)\n",
        "\n",
        "# copy df to avoid defragmentation\n",
        "df = df.copy()\n",
        "\n",
        "# Encode class labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['encoded_class'] = label_encoder.fit_transform(df['flare_class_encoded'])\n",
        "\n",
        "print(\"Encoded Class Distribution:\")\n",
        "print(df['encoded_class'].value_counts())\n",
        "\n",
        "def create_multiclass_splits(df, n_repeats=100):\n",
        "    all_splits = []\n",
        "    for repeat in range(n_repeats):\n",
        "        try:\n",
        "            # Randomly select unique samples for each class\n",
        "            b_class_samples = resample(df[df['encoded_class'] == 0], replace=False, n_samples=128, random_state=repeat)\n",
        "            c_class_samples = resample(df[df['encoded_class'] == 1], replace=False, n_samples=142, random_state=repeat)\n",
        "            m_class_samples = resample(df[df['encoded_class'] == 2], replace=False, n_samples=142, random_state=repeat)\n",
        "            x_class_samples = resample(df[df['encoded_class'] == 3], replace=False, n_samples=23, random_state=repeat)\n",
        "\n",
        "            # Combine selected samples to form a complete dataset\n",
        "            complete_data = pd.concat([b_class_samples, c_class_samples, m_class_samples, x_class_samples])\n",
        "            X = complete_data.drop(columns=['flare_class_encoded', 'encoded_class'])\n",
        "            y = complete_data['encoded_class']  # Encoded multiclass target\n",
        "\n",
        "            if len(X) == len(y):  # Ensure consistent lengths\n",
        "                all_splits.append((X, y))\n",
        "        except ValueError as e:\n",
        "            print(f\"Repeat {repeat}: Error - {e}\")\n",
        "            continue\n",
        "    return all_splits\n",
        "\n",
        "# Function to evaluate model with GridSearchCV\n",
        "def evaluate_model_with_xgboost(X, y, n_splits=10):\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    param_grid = {\n",
        "        'learning_rate': [0.1, 0.9],\n",
        "        'subsample': [0.01, 1]\n",
        "    }\n",
        "\n",
        "    model_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "    grid_search = GridSearchCV(estimator=model_xgb, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "    accuracy_scores = []\n",
        "    roc_auc_scores = []\n",
        "    pr_auc_scores = []\n",
        "    f1_scores = []\n",
        "    fpr_list = []\n",
        "    tpr_list = []\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        best_model_xgb = grid_search.best_estimator_\n",
        "\n",
        "        y_pred = best_model_xgb.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracy_scores.append(accuracy)\n",
        "\n",
        "        y_test_bin = label_binarize(y_test, classes=np.unique(y_train))\n",
        "        test_pred_prob = best_model_xgb.predict_proba(X_test)\n",
        "        roc_auc = roc_auc_score(y_test_bin, test_pred_prob, multi_class='ovr')\n",
        "        roc_auc_scores.append(roc_auc)\n",
        "\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        precision, recall, _ = precision_recall_curve(y_test_bin.ravel(), test_pred_prob.ravel())\n",
        "        pr_auc = average_precision_score(y_test_bin, test_pred_prob)\n",
        "        pr_auc_scores.append(pr_auc)\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(y_test_bin.ravel(), test_pred_prob.ravel())\n",
        "        fpr_list.append(fpr)\n",
        "        tpr_list.append(tpr)\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "\n",
        "    return np.mean(accuracy_scores), np.mean(roc_auc_scores), np.mean(pr_auc_scores), np.mean(f1_scores), accuracy_scores, roc_auc_scores, pr_auc_scores, f1_scores, fpr_list, tpr_list, precision_list, recall_list\n",
        "\n",
        "# Evaluate multiclass classification with 10-fold cross-validation and GridSearchCV\n",
        "multiclass_splits = create_multiclass_splits(df)\n",
        "if len(multiclass_splits) == 0:\n",
        "    print(\"No valid splits created.\")\n",
        "else:\n",
        "    multiclass_results = [evaluate_model_with_xgboost(X, y) for X, y in multiclass_splits]\n",
        "    mean_multiclass_accuracy = np.mean([result[0] for result in multiclass_results])\n",
        "    mean_multiclass_roc_auc = np.mean([result[1] for result in multiclass_results])\n",
        "    mean_multiclass_pr_auc_8PC = np.mean([result[2] for result in multiclass_results])\n",
        "    mean_f1_score = np.mean([result[3] for result in multiclass_results])\n",
        "\n",
        "    print(f\"Mean Multiclass Accuracy: {mean_multiclass_accuracy}\")\n",
        "    print(f\"Mean Multiclass ROC AUC: {mean_multiclass_roc_auc}\")\n",
        "    print(f\"Mean Multiclass PR AUC: {mean_multiclass_pr_auc_8PC}\")\n",
        "    print(f\"Mean Multiclass F1 Score: {mean_f1_score}\")\n",
        "\n",
        "    #  Plot Mean ROC AUC Curve\n",
        "    mean_fpr_8PC = np.linspace(0, 1, 100)\n",
        "    tpr_interpolated_8PC = [np.interp(mean_fpr_8PC, fpr, tpr) for fpr, tpr in zip(multiclass_results[4][8], multiclass_results[4][9]) if isinstance(fpr, np.ndarray) and isinstance(tpr, np.ndarray)]\n",
        "    mean_tpr_8PC = np.mean(tpr_interpolated, axis=0)\n",
        "    mean_tpr_8PC[-1] = 1.0\n",
        "    mean_roc_auc_8PC = auc(mean_fpr_8PC, mean_tpr_8PC)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(mean_fpr_8PC, mean_tpr_8PC, color='green', label=f'Mean ROC (8PC) (AUC = {mean_roc_auc_8PC:.2f})', lw=2, alpha=.8)\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=.8)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate', fontsize=16)\n",
        "    plt.ylabel('True Positive Rate', fontsize=16)\n",
        "    plt.title('Mean ROC AUC Curve', fontsize=18)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.savefig(\"ROC_AUC_curve_XGB_MULTICLASS.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # Plot Mean Precision-Recall Curve\n",
        "    precision_interpolated_8PC = [np.interp(mean_fpr_8PC, np.linspace(0, 1, len(precision)), precision) for precision in multiclass_results[4][10] if isinstance(precision, np.ndarray)]\n",
        "    recall_interpolated_8PC = [np.interp(mean_fpr_8PC, np.linspace(0, 1, len(recall)), recall) for recall in multiclass_results[4][11] if isinstance(recall, np.ndarray)]\n",
        "    mean_precision_8PC = np.mean(precision_interpolated_8PC, axis=0)\n",
        "    mean_recall_8PC = np.mean(recall_interpolated_8PC, axis=0)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(mean_recall_8PC, mean_precision_8PC, color='green', label=f'Mean PR (AUC = {mean_multiclass_pr_auc_8PC:.2f})', lw=2, alpha=.8)\n",
        "    plt.xlabel('Recall', fontsize=16)\n",
        "    plt.ylabel('Precision', fontsize=16)\n",
        "    plt.title('Mean Precision-Recall Curve', fontsize=18)\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.savefig(\"PR_curve_XGB_MULTICLASS.png\")\n",
        "    plt.show()\n",
        "\n",
        "# Print final class distributions for debugging\n",
        "if len(multiclass_splits) > 0:\n",
        "    X, y = multiclass_splits[0]\n",
        "    print(f\"Final Training Set Class Distribution:\\n{y.value_counts()}\")\n"
      ],
      "metadata": {
        "id": "8nXW6Tn2YTIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MULTICLASS CLASSIFICATION - 100PC\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv(\"100 PC.csv\")\n",
        "\n",
        "# Ensure class distributions\n",
        "print(\"Original Class Distribution:\")\n",
        "print(df['flare_class_encoded'].value_counts())\n",
        "\n",
        "# Impute missing values (debugging approach propsed by Gemini AI)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df[df.columns] = imputer.fit_transform(df)\n",
        "\n",
        "# copy df to avoid defragmentation\n",
        "df = df.copy()\n",
        "\n",
        "# Encode class labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['encoded_class'] = label_encoder.fit_transform(df['flare_class_encoded'])\n",
        "\n",
        "print(\"Encoded Class Distribution:\")\n",
        "print(df['encoded_class'].value_counts())\n",
        "\n",
        "def create_multiclass_splits(df, n_repeats=100):\n",
        "    all_splits = []\n",
        "    for repeat in range(n_repeats):\n",
        "        try:\n",
        "            # Randomly select unique samples for each class\n",
        "            b_class_samples = resample(df[df['encoded_class'] == 0], replace=False, n_samples=128, random_state=repeat)\n",
        "            c_class_samples = resample(df[df['encoded_class'] == 1], replace=False, n_samples=142, random_state=repeat)\n",
        "            m_class_samples = resample(df[df['encoded_class'] == 2], replace=False, n_samples=142, random_state=repeat)\n",
        "            x_class_samples = resample(df[df['encoded_class'] == 3], replace=False, n_samples=23, random_state=repeat)\n",
        "\n",
        "            # Combine selected samples to form a complete dataset\n",
        "            complete_data = pd.concat([b_class_samples, c_class_samples, m_class_samples, x_class_samples])\n",
        "            X = complete_data.drop(columns=['flare_class_encoded', 'encoded_class'])\n",
        "            y = complete_data['encoded_class']  # Encoded multiclass target\n",
        "\n",
        "            if len(X) == len(y):  # Ensure consistent lengths\n",
        "                all_splits.append((X, y))\n",
        "        except ValueError as e:\n",
        "            print(f\"Repeat {repeat}: Error - {e}\")\n",
        "            continue\n",
        "    return all_splits\n",
        "\n",
        "# Function to evaluate model with GridSearchCV\n",
        "def evaluate_model_with_xgboost(X, y, n_splits=10):\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    param_grid = {\n",
        "        'learning_rate': [0.1, 0.9],\n",
        "        'subsample': [0.01, 1]\n",
        "    }\n",
        "\n",
        "    model_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "    grid_search = GridSearchCV(estimator=model_xgb, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "    accuracy_scores = []\n",
        "    roc_auc_scores = []\n",
        "    pr_auc_scores = []\n",
        "    f1_scores = []\n",
        "    fpr_list = []\n",
        "    tpr_list = []\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        best_model_xgb = grid_search.best_estimator_\n",
        "\n",
        "        y_pred = best_model_xgb.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracy_scores.append(accuracy)\n",
        "\n",
        "        y_test_bin = label_binarize(y_test, classes=np.unique(y_train))\n",
        "        test_pred_prob = best_model_xgb.predict_proba(X_test)\n",
        "        roc_auc = roc_auc_score(y_test_bin, test_pred_prob, multi_class='ovr')\n",
        "        roc_auc_scores.append(roc_auc)\n",
        "\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        precision, recall, _ = precision_recall_curve(y_test_bin.ravel(), test_pred_prob.ravel())\n",
        "        pr_auc = average_precision_score(y_test_bin, test_pred_prob)\n",
        "        pr_auc_scores.append(pr_auc)\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(y_test_bin.ravel(), test_pred_prob.ravel())\n",
        "        fpr_list.append(fpr)\n",
        "        tpr_list.append(tpr)\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "\n",
        "    return np.mean(accuracy_scores), np.mean(roc_auc_scores), np.mean(pr_auc_scores), np.mean(f1_scores), accuracy_scores, roc_auc_scores, pr_auc_scores, f1_scores, fpr_list, tpr_list, precision_list, recall_list\n",
        "\n",
        "# Evaluate multiclass classification with 10-fold cross-validation and GridSearchCV\n",
        "multiclass_splits = create_multiclass_splits(df_pca)\n",
        "if len(multiclass_splits) == 0:\n",
        "    print(\"No valid splits created.\")\n",
        "else:\n",
        "    multiclass_results = [evaluate_model_with_xgboost(X, y) for X, y in multiclass_splits]\n",
        "    mean_multiclass_accuracy = np.mean([result[0] for result in multiclass_results])\n",
        "    mean_multiclass_roc_auc = np.mean([result[1] for result in multiclass_results])\n",
        "    mean_multiclass_pr_auc_100PC = np.mean([result[2] for result in multiclass_results])\n",
        "    mean_f1_score = np.mean([result[3] for result in multiclass_results])\n",
        "\n",
        "    print(f\"Mean Multiclass Accuracy: {mean_multiclass_accuracy}\")\n",
        "    print(f\"Mean Multiclass ROC AUC: {mean_multiclass_roc_auc}\")\n",
        "    print(f\"Mean Multiclass PR AUC: {mean_multiclass_pr_auc_100PC}\")\n",
        "    print(f\"Mean Multiclass F1 Score: {mean_f1_score}\")\n",
        "\n",
        "     # combined Plot Mean ROC AUC Curve (8;100 PC)\n",
        "    mean_fpr_100PC = np.linspace(0, 1, 100)\n",
        "    tpr_interpolated_100PC = [np.interp(mean_fpr_100PC, fpr, tpr) for fpr, tpr in zip(multiclass_results[4][8], multiclass_results[4][9]) if isinstance(fpr, np.ndarray) and isinstance(tpr, np.ndarray)]\n",
        "    mean_tpr_100PC = np.mean(tpr_interpolated, axis=0)\n",
        "    mean_tpr_100PC[-1] = 1.0\n",
        "    mean_roc_auc_100PC = auc(mean_fpr_100PC, mean_tpr_100PC)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(mean_fpr_8PC, mean_tpr_8PC, color='blue', label=f'Mean ROC (8PC) (AUC = {mean_roc_auc_8PC:.2f})', lw=2, alpha=.8)\n",
        "    plt.plot(mean_fpr_100PC, mean_tpr_100PC, color='orange', label=f'Mean ROC (100PC) (AUC = {mean_roc_auc_100PC:.2f})', lw=2, alpha=.8)\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=.8)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate', fontsize=16)\n",
        "    plt.ylabel('True Positive Rate', fontsize=16)\n",
        "    plt.title('Mean ROC AUC Curve', fontsize=18)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.savefig(\"ROC_AUC_curve_XGB_MULTICLASS.png\")\n",
        "    plt.show()\n",
        "\n",
        "     # combined Plot Mean PR Curve (8;100 PC)\n",
        "    precision_interpolated_100PC = [np.interp(mean_fpr_100PC, np.linspace(0, 1, len(precision)), precision) for precision in multiclass_results[4][10] if isinstance(precision, np.ndarray)]\n",
        "    recall_interpolated_100PC = [np.interp(mean_fpr_100PC, np.linspace(0, 1, len(recall)), recall) for recall in multiclass_results[4][11] if isinstance(recall, np.ndarray)]\n",
        "    mean_precision_100PC = np.mean(precision_interpolated_100PC, axis=0)\n",
        "    mean_recall_100PC = np.mean(recall_interpolated_100PC, axis=0)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(mean_recall_8PC, mean_precision_8PC, color='blue', label=f'Mean PR (8PC) (AUC = {mean_multiclass_pr_auc_8PC:.2f})', lw=2, alpha=.8)\n",
        "    plt.plot(mean_recall_100PC, mean_precision_100PC, color='orange', label=f'Mean PR (100PC) (AUC = {mean_multiclass_pr_auc_100PC:.2f})', lw=2, alpha=.8)\n",
        "    plt.xlabel('Recall', fontsize=16)\n",
        "    plt.ylabel('Precision', fontsize=16)\n",
        "    plt.title('Mean Precision-Recall Curve', fontsize=18)\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.savefig(\"PR_curve_XGB_MULTICLASS.png\")\n",
        "    plt.show()\n",
        "\n",
        "# Print final class distributions for debugging\n",
        "if len(multiclass_splits) > 0:\n",
        "    X, y = multiclass_splits[0]\n",
        "    print(f\"Final Training Set Class Distribution:\\n{y.value_counts()}\")\n"
      ],
      "metadata": {
        "id": "jNm6vk1zrlHa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}